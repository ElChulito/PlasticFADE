{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d6e080-6b24-4c40-af82-77be603f2f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Process Parameter  Estimate Standard deviation\n",
      "42  PP degradation       x_i  3.56e-03           3.48e-03\n",
      "43             NaN     tau_i  1.52e-03           1.06e-01\n",
      "44             NaN       y_i  2.48e-02           4.98e-04\n",
      "45             NaN   theta_i  7.61e-01           3.83e-01\n",
      "46             NaN       z_i  2.71e-05           6.37e-05\n",
      "47             NaN     eta_i  4.41e-01           1.09e-01\n",
      "\n",
      "   Polymer & Size & Shape SA:V [cm-1] I_j_WC [W/m2] \\tC_j_WC [CFU/ml]\n",
      "0    PP, 1000 μm, sphere          60             0             38500\n",
      "1     PP, 100 μm, sphere         600             0             38500\n",
      "2      PP, 10 μm, sphere        6000             0             38500\n",
      "\n",
      "    k_point  CI_lower  CI_upper\n",
      "0 1.02e-05  4.14e-06  3.15e-05\n",
      "1 1.02e-05  4.15e-06  3.16e-05\n",
      "2 1.03e-05  4.16e-06  3.08e-05\n"
     ]
    }
   ],
   "source": [
    "# 95% CI calculation (PP, with Elena's inputs, from Monte Carlo)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlwings as xw\n",
    "pd.set_option('display.float_format', '{:.2e}'.format)\n",
    "file_path = \"/Users/elchulito/Library/CloudStorage/OneDrive-polymtlus/0 - A_Database and methodology_PhD/PlasticFADE.xlsx\"\n",
    "sheet_name = \"Uncertainty\"\n",
    "data_CI_left = pd.read_excel(file_path, sheet_name=sheet_name, usecols=\"A:D\", skiprows=1)\n",
    "data_CI_PP = data_CI_left.iloc[42:48] # Row index minus 3, change this range for other polymers\n",
    "print(data_CI_PP)\n",
    "x_i, tau_i, y_i, theta_i, z_i, eta_i = data_CI_PP.iloc[:, 2].values\n",
    "x_i_std, tau_i_std, y_i_std, theta_i_std, z_i_std, eta_i_std = data_CI_PP.iloc[:, 3].values\n",
    "\n",
    "data_input = pd.read_excel(file_path, sheet_name=\"Elena2023\", usecols=\"A,B,E,F\", skiprows=1)\n",
    "input_PP = data_input.iloc[0:3, :]  # Change for other different polymers\n",
    "print(\"\\n\", input_PP)\n",
    "input_PP.columns = ['Polymer & Size & Shape', 's', 'I_j', 'C_j']\n",
    "\n",
    "# Monte Carlo setup\n",
    "N = 10000\n",
    "np.random.seed(42)\n",
    "results = []\n",
    "# Loop through each row of input\n",
    "for index, row in input_PP.iterrows():\n",
    "    s = row['s']\n",
    "    I_j = row['I_j']\n",
    "    C_j = row['C_j']\n",
    "    x_i_samples = np.random.lognormal(np.log(x_i), x_i_std, N)\n",
    "    tau_i_samples = np.random.lognormal(np.log(tau_i), tau_i_std, N)\n",
    "    y_i_samples = np.random.lognormal(np.log(y_i), y_i_std, N)\n",
    "    theta_i_samples = np.random.lognormal(np.log(theta_i), theta_i_std, N)\n",
    "    z_i_samples = np.random.lognormal(np.log(z_i), z_i_std, N)\n",
    "    eta_i_samples = np.random.lognormal(np.log(eta_i), eta_i_std, N)\n",
    "    k_samples = x_i_samples * (s**tau_i_samples) * (y_i_samples * I_j**theta_i_samples + z_i_samples * C_j**eta_i_samples)\n",
    "    k_samples = k_samples[np.isfinite(k_samples)]  # Filter invalid samples\n",
    "    log_k = np.log10(k_samples)\n",
    "    log_lower = np.percentile(log_k, 2.5)\n",
    "    log_upper = np.percentile(log_k, 97.5)\n",
    "    lower_bound = 10 ** log_lower\n",
    "    upper_bound = 10 ** log_upper\n",
    "    k_point = x_i * (s**tau_i) * (y_i * I_j**theta_i + z_i * C_j**eta_i) # Point estimate of k_degr\n",
    "    results.append({'k_point': k_point, 'CI_lower': lower_bound, 'CI_upper': upper_bound})\n",
    "results_CI = pd.DataFrame(results)\n",
    "print(\"\\n\", results_CI)\n",
    "\n",
    "wb = xw.Book(file_path)  # file_path is your existing Excel file path\n",
    "sheet = wb.sheets[\"Elena2023\"]\n",
    "start_row = 3  # Change this index for other polymers\n",
    "sheet.range(f'N{start_row}').options(index=False, header=False).value = results_CI['CI_lower'].values.reshape(-1, 1)\n",
    "sheet.range(f'O{start_row}').options(index=False, header=False).value = results_CI['CI_upper'].values.reshape(-1, 1)\n",
    "wb.save()\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d471d7-a006-4f02-82ed-975c2442e766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Process Parameter  Estimate Standard deviation\n",
      "54  PS degradation       x_i  2.40e-04           2.11e-04\n",
      "55             NaN     tau_i  2.30e-01           7.45e-02\n",
      "56             NaN       y_i  1.44e-02           5.97e-06\n",
      "57             NaN   theta_i  1.07e+00           1.89e-01\n",
      "58             NaN       z_i  1.22e-04           3.27e-04\n",
      "59             NaN     eta_i  4.73e-01           1.09e-01\n",
      "\n",
      "   Polymer & Size & Shape SA:V [cm-1] I_j_WC [W/m2] \\tC_j_WC [CFU/ml]\n",
      "3    PS, 1000 μm, sphere          60             0             38500\n",
      "4     PS, 100 μm, sphere         600             0             38500\n",
      "5      PS, 10 μm, sphere        6000             0             38500\n",
      "\n",
      "    k_point  CI_lower  CI_upper\n",
      "0 1.10e-05  4.18e-06  3.75e-05\n",
      "1 1.87e-05  6.93e-06  6.46e-05\n",
      "2 3.18e-05  1.17e-05  1.08e-04\n"
     ]
    }
   ],
   "source": [
    "# 95% CI calculation (PS, with Elena's inputs, from Monte Carlo)\n",
    "pd.set_option('display.float_format', '{:.2e}'.format)\n",
    "file_path = \"/Users/elchulito/Library/CloudStorage/OneDrive-polymtlus/0 - A_Database and methodology_PhD/PlasticFADE.xlsx\"\n",
    "sheet_name = \"Uncertainty\"\n",
    "# data_CI_left = pd.read_excel(file_path, sheet_name=sheet_name, usecols=\"A:D\", skiprows=1)\n",
    "data_CI_PS = data_CI_left.iloc[54:60] # Row index minus 3, change this range for other polymers\n",
    "print(data_CI_PS)\n",
    "x_i, tau_i, y_i, theta_i, z_i, eta_i = data_CI_PS.iloc[:, 2].values\n",
    "x_i_std, tau_i_std, y_i_std, theta_i_std, z_i_std, eta_i_std = data_CI_PS.iloc[:, 3].values\n",
    "# data_input = pd.read_excel(file_path, sheet_name=\"Elena2023\", usecols=\"A,B,E,F\", skiprows=1)\n",
    "input_PS = data_input.iloc[3:6, :]  # Change for other different polymers\n",
    "print(\"\\n\", input_PS)\n",
    "input_PS.columns = ['Polymer & Size & Shape', 's', 'I_j', 'C_j']\n",
    "\n",
    "# Monte Carlo setup\n",
    "N = 10000\n",
    "np.random.seed(42)\n",
    "results = []\n",
    "# Loop through each row of input\n",
    "for index, row in input_PP.iterrows():\n",
    "    s = row['s']\n",
    "    I_j = row['I_j']\n",
    "    C_j = row['C_j']\n",
    "    x_i_samples = np.random.lognormal(np.log(x_i), x_i_std, N)\n",
    "    tau_i_samples = np.random.lognormal(np.log(tau_i), tau_i_std, N)\n",
    "    y_i_samples = np.random.lognormal(np.log(y_i), y_i_std, N)\n",
    "    theta_i_samples = np.random.lognormal(np.log(theta_i), theta_i_std, N)\n",
    "    z_i_samples = np.random.lognormal(np.log(z_i), z_i_std, N)\n",
    "    eta_i_samples = np.random.lognormal(np.log(eta_i), eta_i_std, N)\n",
    "    k_samples = x_i_samples * (s**tau_i_samples) * (y_i_samples * I_j**theta_i_samples + z_i_samples * C_j**eta_i_samples)\n",
    "    k_samples = k_samples[np.isfinite(k_samples)]  # Filter invalid samples\n",
    "    log_k = np.log10(k_samples)\n",
    "    log_lower = np.percentile(log_k, 2.5)\n",
    "    log_upper = np.percentile(log_k, 97.5)\n",
    "    lower_bound = 10 ** log_lower\n",
    "    upper_bound = 10 ** log_upper\n",
    "    k_point = x_i * (s**tau_i) * (y_i * I_j**theta_i + z_i * C_j**eta_i) # Point estimate of k_degr\n",
    "    results.append({'k_point': k_point, 'CI_lower': lower_bound, 'CI_upper': upper_bound})\n",
    "results_CI = pd.DataFrame(results)\n",
    "print(\"\\n\", results_CI)\n",
    "\n",
    "wb = xw.Book(file_path)  # file_path is your existing Excel file path\n",
    "sheet = wb.sheets[\"Elena2023\"]\n",
    "start_row = 6  # Change this index for other polymers\n",
    "sheet.range(f'N{start_row}').options(index=False, header=False).value = results_CI['CI_lower'].values.reshape(-1, 1)\n",
    "sheet.range(f'O{start_row}').options(index=False, header=False).value = results_CI['CI_upper'].values.reshape(-1, 1)\n",
    "wb.save()\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6d5a659-04dd-48fb-975b-d1a347fdb531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Process.1 Parameter.1  Estimate.1  Standard deviation.1\n",
      "6   PET degradation         x_i    2.60e-04              3.16e-04\n",
      "7               NaN       tau_i    7.91e-01              1.93e-01\n",
      "8               NaN         y_i    7.39e-06              1.25e-05\n",
      "9               NaN     theta_i    2.00e+00              2.38e-01\n",
      "10              NaN         z_i    1.42e-02              4.91e-06\n",
      "11              NaN       eta_i    7.84e-02              4.57e-02\n",
      "\n",
      "   Polymer & Size & Shape SA:V [cm-1] I_j_WC [W/m2] \\tC_j_WC [CFU/ml]\n",
      "6   PET, 1000 μm, sphere          60             0             38500\n",
      "7    PET, 100 μm, sphere         600             0             38500\n",
      "8     PET, 10 μm, sphere        6000             0             38500\n",
      "\n",
      "    k_point  CI_lower  CI_upper\n",
      "0 2.16e-04  7.79e-05  9.68e-04\n",
      "1 1.34e-03  2.70e-04  1.43e-02\n",
      "2 8.25e-03  9.20e-04  2.08e-01\n"
     ]
    }
   ],
   "source": [
    "# 95% CI calculation (PET, with Elena's inputs, from Monte Carlo)\n",
    "pd.set_option('display.float_format', '{:.2e}'.format)\n",
    "file_path = \"/Users/elchulito/Library/CloudStorage/OneDrive-polymtlus/0 - A_Database and methodology_PhD/PlasticFADE.xlsx\"\n",
    "sheet_name = \"Uncertainty\"\n",
    "data_CI_right = pd.read_excel(file_path, sheet_name=sheet_name, usecols=\"F:I\", skiprows=1)\n",
    "data_CI_PET = data_CI_right.iloc[6:12] # Row index minus 3, change this range for other polymers\n",
    "print(data_CI_PET)\n",
    "x_i, tau_i, y_i, theta_i, z_i, eta_i = data_CI_PET.iloc[:, 2].values\n",
    "x_i_std, tau_i_std, y_i_std, theta_i_std, z_i_std, eta_i_std = data_CI_PET.iloc[:, 3].values\n",
    "# data_input = pd.read_excel(file_path, sheet_name=\"Elena2023\", usecols=\"A,B,E,F\", skiprows=1)\n",
    "input_PET = data_input.iloc[6:9, :]  # Change for other different polymers\n",
    "print(\"\\n\", input_PET)\n",
    "input_PET.columns = ['Polymer & Size & Shape', 's', 'I_j', 'C_j']\n",
    "\n",
    "# Monte Carlo setup\n",
    "N = 10000\n",
    "np.random.seed(42)\n",
    "results = []\n",
    "# Loop through each row of input\n",
    "for index, row in input_PP.iterrows():\n",
    "    s = row['s']\n",
    "    I_j = row['I_j']\n",
    "    C_j = row['C_j']\n",
    "    x_i_samples = np.random.lognormal(np.log(x_i), x_i_std, N)\n",
    "    tau_i_samples = np.random.lognormal(np.log(tau_i), tau_i_std, N)\n",
    "    y_i_samples = np.random.lognormal(np.log(y_i), y_i_std, N)\n",
    "    theta_i_samples = np.random.lognormal(np.log(theta_i), theta_i_std, N)\n",
    "    z_i_samples = np.random.lognormal(np.log(z_i), z_i_std, N)\n",
    "    eta_i_samples = np.random.lognormal(np.log(eta_i), eta_i_std, N)\n",
    "    k_samples = x_i_samples * (s**tau_i_samples) * (y_i_samples * I_j**theta_i_samples + z_i_samples * C_j**eta_i_samples)\n",
    "    k_samples = k_samples[np.isfinite(k_samples)]  # Filter invalid samples\n",
    "    log_k = np.log10(k_samples)\n",
    "    log_lower = np.percentile(log_k, 2.5)\n",
    "    log_upper = np.percentile(log_k, 97.5)\n",
    "    lower_bound = 10 ** log_lower\n",
    "    upper_bound = 10 ** log_upper\n",
    "    k_point = x_i * (s**tau_i) * (y_i * I_j**theta_i + z_i * C_j**eta_i) # Point estimate of k_degr\n",
    "    results.append({'k_point': k_point, 'CI_lower': lower_bound, 'CI_upper': upper_bound})\n",
    "results_CI = pd.DataFrame(results)\n",
    "print(\"\\n\", results_CI)\n",
    "\n",
    "wb = xw.Book(file_path)  # file_path is your existing Excel file path\n",
    "sheet = wb.sheets[\"Elena2023\"]\n",
    "start_row = 9  # Change this index for other polymers\n",
    "sheet.range(f'N{start_row}').options(index=False, header=False).value = results_CI['CI_lower'].values.reshape(-1, 1)\n",
    "sheet.range(f'O{start_row}').options(index=False, header=False).value = results_CI['CI_upper'].values.reshape(-1, 1)\n",
    "wb.save()\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c94b7972-1108-4661-9ae5-a170337b8fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Process Parameter  Estimate Standard deviation\n",
      "6   HDPE degradation       x_i  3.45e-03           5.30e-03\n",
      "7                NaN     tau_i  3.76e-11           1.81e-01\n",
      "8                NaN       y_i  5.93e-03           3.93e-03\n",
      "9                NaN   theta_i  3.29e-01           6.24e-01\n",
      "10               NaN       z_i  1.23e-03           4.68e-03\n",
      "11               NaN     eta_i  2.12e-01           1.68e-01\n",
      "\n",
      "    Polymer & Size & Shape SA:V [cm-1] I_j_WC [W/m2] \\tC_j_WC [CFU/ml]\n",
      "9   HDPE, 1000 μm, sphere          60             0             38500\n",
      "10   HDPE, 100 μm, sphere         600             0             38500\n",
      "11    HDPE, 10 μm, sphere        6000             0             38500\n",
      "\n",
      "    k_point  CI_lower  CI_upper\n",
      "0 3.99e-05  2.12e-05  9.71e-05\n",
      "1 3.99e-05  2.12e-05  9.69e-05\n",
      "2 3.99e-05  2.12e-05  9.51e-05\n"
     ]
    }
   ],
   "source": [
    "# 95% CI calculation (HDPE, with Elena's inputs, from Monte Carlo)\n",
    "pd.set_option('display.float_format', '{:.2e}'.format)\n",
    "file_path = \"/Users/elchulito/Library/CloudStorage/OneDrive-polymtlus/0 - A_Database and methodology_PhD/PlasticFADE.xlsx\"\n",
    "sheet_name = \"Uncertainty\"\n",
    "# data_CI_left = pd.read_excel(file_path, sheet_name=sheet_name, usecols=\"A:D\", skiprows=1)\n",
    "data_CI_HDPE = data_CI_left.iloc[6:12] # Row index minus 3, change this range for other polymers\n",
    "print(data_CI_HDPE)\n",
    "x_i, tau_i, y_i, theta_i, z_i, eta_i = data_CI_HDPE.iloc[:, 2].values\n",
    "x_i_std, tau_i_std, y_i_std, theta_i_std, z_i_std, eta_i_std = data_CI_HDPE.iloc[:, 3].values\n",
    "# data_input = pd.read_excel(file_path, sheet_name=\"Elena2023\", usecols=\"A,B,E,F\", skiprows=1)\n",
    "input_HDPE = data_input.iloc[9:12, :]  # Change for other different polymers\n",
    "print(\"\\n\", input_HDPE)\n",
    "input_HDPE.columns = ['Polymer & Size & Shape', 's', 'I_j', 'C_j']\n",
    "\n",
    "# Monte Carlo setup\n",
    "N = 10000\n",
    "np.random.seed(42)\n",
    "results = []\n",
    "# Loop through each row of input\n",
    "for index, row in input_PP.iterrows():\n",
    "    s = row['s']\n",
    "    I_j = row['I_j']\n",
    "    C_j = row['C_j']\n",
    "    x_i_samples = np.random.lognormal(np.log(x_i), x_i_std, N)\n",
    "    tau_i_samples = np.random.lognormal(np.log(tau_i), tau_i_std, N)\n",
    "    y_i_samples = np.random.lognormal(np.log(y_i), y_i_std, N)\n",
    "    theta_i_samples = np.random.lognormal(np.log(theta_i), theta_i_std, N)\n",
    "    z_i_samples = np.random.lognormal(np.log(z_i), z_i_std, N)\n",
    "    eta_i_samples = np.random.lognormal(np.log(eta_i), eta_i_std, N)\n",
    "    k_samples = x_i_samples * (s**tau_i_samples) * (y_i_samples * I_j**theta_i_samples + z_i_samples * C_j**eta_i_samples)\n",
    "    k_samples = k_samples[np.isfinite(k_samples)]  # Filter invalid samples\n",
    "    log_k = np.log10(k_samples)\n",
    "    log_lower = np.percentile(log_k, 2.5)\n",
    "    log_upper = np.percentile(log_k, 97.5)\n",
    "    lower_bound = 10 ** log_lower\n",
    "    upper_bound = 10 ** log_upper\n",
    "    k_point = x_i * (s**tau_i) * (y_i * I_j**theta_i + z_i * C_j**eta_i) # Point estimate of k_degr\n",
    "    results.append({'k_point': k_point, 'CI_lower': lower_bound, 'CI_upper': upper_bound})\n",
    "results_CI = pd.DataFrame(results)\n",
    "print(\"\\n\", results_CI)\n",
    "\n",
    "wb = xw.Book(file_path)  # file_path is your existing Excel file path\n",
    "sheet = wb.sheets[\"Elena2023\"]\n",
    "start_row = 12  # Change this index for other polymers\n",
    "sheet.range(f'N{start_row}').options(index=False, header=False).value = results_CI['CI_lower'].values.reshape(-1, 1)\n",
    "sheet.range(f'O{start_row}').options(index=False, header=False).value = results_CI['CI_upper'].values.reshape(-1, 1)\n",
    "wb.save()\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8da4e212-7c7e-486d-9a87-e59ad3215ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Process Parameter  Estimate Standard deviation\n",
      "18  LDPE degradation       x_i  1.10e-02           5.75e-03\n",
      "19               NaN     tau_i  5.00e-13           1.10e-01\n",
      "20               NaN       y_i  1.04e-02           6.07e-03\n",
      "21               NaN   theta_i  4.38e-03           5.03e-05\n",
      "22               NaN       z_i  1.06e-04           4.47e-04\n",
      "23               NaN     eta_i  3.24e-01           1.92e-01\n",
      "\n",
      "    Polymer & Size & Shape SA:V [cm-1] I_j_WC [W/m2] \\tC_j_WC [CFU/ml]\n",
      "12  LDPE, 1000 μm, sphere          60             0             38500\n",
      "13   LDPE, 100 μm, sphere         600             0             38500\n",
      "14    LDPE, 10 μm, sphere        6000             0             38500\n",
      "\n",
      "    k_point  CI_lower  CI_upper\n",
      "0 3.54e-05  1.20e-05  1.75e-04\n",
      "1 3.54e-05  1.20e-05  1.74e-04\n",
      "2 3.54e-05  1.20e-05  1.68e-04\n"
     ]
    }
   ],
   "source": [
    "# 95% CI calculation (LDPE, with Elena's inputs, from Monte Carlo)\n",
    "pd.set_option('display.float_format', '{:.2e}'.format)\n",
    "file_path = \"/Users/elchulito/Library/CloudStorage/OneDrive-polymtlus/0 - A_Database and methodology_PhD/PlasticFADE.xlsx\"\n",
    "sheet_name = \"Uncertainty\"\n",
    "# data_CI_left = pd.read_excel(file_path, sheet_name=sheet_name, usecols=\"A:D\", skiprows=1)\n",
    "data_CI_LDPE = data_CI_left.iloc[18:24] # Row index minus 3, change this range for other polymers\n",
    "print(data_CI_LDPE)\n",
    "x_i, tau_i, y_i, theta_i, z_i, eta_i = data_CI_LDPE.iloc[:, 2].values\n",
    "x_i_std, tau_i_std, y_i_std, theta_i_std, z_i_std, eta_i_std = data_CI_LDPE.iloc[:, 3].values\n",
    "# data_input = pd.read_excel(file_path, sheet_name=\"Elena2023\", usecols=\"A,B,E,F\", skiprows=1)\n",
    "input_LDPE = data_input.iloc[12:15, :]  # Change for other different polymers\n",
    "print(\"\\n\", input_LDPE)\n",
    "input_LDPE.columns = ['Polymer & Size & Shape', 's', 'I_j', 'C_j']\n",
    "\n",
    "# Monte Carlo setup\n",
    "N = 10000\n",
    "np.random.seed(42)\n",
    "results = []\n",
    "# Loop through each row of input\n",
    "for index, row in input_PP.iterrows():\n",
    "    s = row['s']\n",
    "    I_j = row['I_j']\n",
    "    C_j = row['C_j']\n",
    "    x_i_samples = np.random.lognormal(np.log(x_i), x_i_std, N)\n",
    "    tau_i_samples = np.random.lognormal(np.log(tau_i), tau_i_std, N)\n",
    "    y_i_samples = np.random.lognormal(np.log(y_i), y_i_std, N)\n",
    "    theta_i_samples = np.random.lognormal(np.log(theta_i), theta_i_std, N)\n",
    "    z_i_samples = np.random.lognormal(np.log(z_i), z_i_std, N)\n",
    "    eta_i_samples = np.random.lognormal(np.log(eta_i), eta_i_std, N)\n",
    "    k_samples = x_i_samples * (s**tau_i_samples) * (y_i_samples * I_j**theta_i_samples + z_i_samples * C_j**eta_i_samples)\n",
    "    k_samples = k_samples[np.isfinite(k_samples)]  # Filter invalid samples\n",
    "    log_k = np.log10(k_samples)\n",
    "    log_lower = np.percentile(log_k, 2.5)\n",
    "    log_upper = np.percentile(log_k, 97.5)\n",
    "    lower_bound = 10 ** log_lower\n",
    "    upper_bound = 10 ** log_upper\n",
    "    k_point = x_i * (s**tau_i) * (y_i * I_j**theta_i + z_i * C_j**eta_i) # Point estimate of k_degr\n",
    "    results.append({'k_point': k_point, 'CI_lower': lower_bound, 'CI_upper': upper_bound})\n",
    "results_CI = pd.DataFrame(results)\n",
    "print(\"\\n\", results_CI)\n",
    "\n",
    "wb = xw.Book(file_path)  # file_path is your existing Excel file path\n",
    "sheet = wb.sheets[\"Elena2023\"]\n",
    "start_row = 15  # Change this index for other polymers\n",
    "sheet.range(f'N{start_row}').options(index=False, header=False).value = results_CI['CI_lower'].values.reshape(-1, 1)\n",
    "sheet.range(f'O{start_row}').options(index=False, header=False).value = results_CI['CI_upper'].values.reshape(-1, 1)\n",
    "wb.save()\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5978cfd8-2524-45a8-9344-f0a05a2084cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
